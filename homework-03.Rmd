---
title: "homework_03"
author: "Sanjana Sujeet"
date: "2025-05-28"
format: html
#output: html_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(janitor)
library(here)
library(gt)
library(dplyr)
library(ggplot2)
library(magick)
```


**GitHub Repository:** [https://github.com/sanjanasujeet/ENVS-193DS_workshop-07](https://github.com/sanjanasujeet/ENVS-193DS_workshop-07)

# 1. Personal Data
## 1A. Data Summarizing

The main thing that I want to look at from my data is how stress levels affect the pace of my reading.  

I will analyze my reading pace by dividing 'pages read' by 'hours reading' and compare this to 'quantified daily stress level', which I calculated based on the number of upcoming assignments and tests as well as my perceived stress, to see if stress influences the pace that I read.

To summarize my data, I will calculate the median and range of my reading pace across different stress levels (low, medium, high stress) to see if stress impacts not just how fast I read within these stress levels, but also how much variation there is. Comparing medians and range through boxplots within stress levels is informative because it is a simple way to visualize if there is a difference between how different stress levels affect me and how consistently they affect me. I may read less efficiently when I feel overwhelmed, or I may read quicker when trying to avoid stress through a calming activity. I may consistently read faster in high stress levels or it could fluctuate more in higher stress levels. Median and Range could answer these questions.

#### cleaning data

```{r}
data<- read.csv("data/springtracking2.csv") #read in data
data_clean<-clean_names(data) #cleaning column names
data_clean <- data_clean |> 
  rename(hours = hours_of_activity) #shortens name cuz i think i will be using it often
data_clean <- data_clean |> 
  mutate(pace = pages_read / hours) #creates new column pace which is pages/min
data_clean <- data_clean %>%
  mutate(pace = replace(pace, is.nan(pace), 0))# removes NaN and makes them 0 instead(this was a calculation issue)
data_clean <- data_clean %>%
  mutate(stress_level = case_when(
    quantified_stress >= 0 & quantified_stress <= 9  ~ "low",
    quantified_stress >= 10 & quantified_stress <= 19 ~ "medium",
    quantified_stress >= 20 ~ "high")) # creates new column called stress_level and takes quantified stress levels and makes 3 levels out of it

data_clean <- data_clean %>%
  mutate(stress_level = factor(stress_level, levels = c("low", "medium", "high"))) # orders the levels

```


```{r, message=FALSE, echo=FALSE, eval= FALSE}
#preliminary graphing

ggplot(data_clean %>% 
         filter(!is.na(quantified_stress), !is.na(pages_read)),
       aes(x = quantified_stress, y = pages_read)) +
  geom_point(color = "cyan4", alpha = 0.7, size = 2) +
  geom_smooth(method = "lm", color = "royalblue", se = TRUE) +
  labs(
    title = "Pages Read vs. Quantified Stress",
    x = "Quantified Stress",
    y = "Pages Read"
  ) +
  theme_minimal()

```

```{r, message=FALSE, echo=FALSE, eval= FALSE}
ggplot(data_clean |> filter(!is.na(stress_level), !is.na(pages_read)),
       aes(x = stress_level, y = pages_read, fill = stress_level)) +
  geom_boxplot() +
  scale_fill_manual(values = c("low" = "lightblue", "medium" = "cadetblue", "high" = "cyan4")) +
  labs(
    title = "Pages Read by Stress Level",
    x = "Stress Level",
    y = "Pages Read"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

```

```{r, message=FALSE, echo=FALSE, eval= FALSE}
ggplot(data_clean %>% 
         filter(!is.na(quantified_stress), !is.na(pace), pace != 0),
       aes(x = quantified_stress, y = pages_read)) +
  geom_point(color = "salmon", alpha = 0.7, size = 2) +
  geom_smooth(method = "lm", color = "darkred", se = TRUE) +
  labs(
    title = "Pace vs. Quantified Stress (Excluding no reading days)",
    x = "Quantified Stress",
    y = "Pace(pages per hour)"
  ) +
  theme_minimal()

```

## 1B. Visualization

```{r}
ggplot(data_clean |> filter(pace != 0),#removes anywhere pace is 0(meaning i didnt read that day)
       aes(x = stress_level, y = pace, fill = stress_level)) +#sets x and y and colors based on stress level
  geom_boxplot() +#makes boxplot
  geom_jitter(width = 0.1, height = 0, size = 2)+#adds underlying data points
  stat_summary(fun = mean, geom = "point", size = 3, color = "red")+#adds mean as a red dot
  scale_fill_manual(values = c("low" = "lightgreen", "medium" = "#FFFF66", "high" = "coral")) +#manually inputs colors
  labs(
    title = "Reading Pace by Stress Level (Excluding no reading days)", #title
    x = "Stress Level", #xaxis
    y = "Pace(Pages per Hour)" #yaxis
  ) +
  theme_minimal() + #clean background
  theme(legend.position = "none") #remove legend
```

## 1C. Caption
**Figure: Reading Pace by Stress Level (Excluding Days with No Reading)**

This boxplot shows the distribution of reading pace, measured in pages per hour, across three calculated stress levels: low, medium, and high. The stress levels are distinguished on the x axis and by color with light green on the low stress level box plot, yellow on the medium stress level, and coral on the high stress level. The bold black line inside the box represents the group's median and just by looking at medians, there is a correlation between higher pace and lower stress levels. However, then looking at the rest of the box, with the top and bottom representing the 1st and 3rd quartiles and the whiskers representing minimum and maximum, there is too much overlap between groups to draw significant conclusions just from the graph. The black points on and around the box and whisker plots represent individual daily pace data and the large vertical range of the points show that the data is too spread out to draw conclusions. The larger red dot represents the mean which is relatively close to the median but one difference is that the low stress mean is less than the medium stress mean, unlike their corresponding medians. The range, or height of the box, shows us that during days of low stress levels there is high variability but days of high stress have a more compressed range and consistently read fewer pages per hour than medium stress level days. 

## 1D. Table Presentation
```{r}
# Summarize stats of reading pace by stress level
summary_table <- data_clean %>%
  filter(pace != 0) %>% #removes days i didnt read
  group_by(stress_level) %>% #groups by low medium high stress
  summarise(
    Min = round(min(pace)), # minimum of pace
    Q1 = round(quantile(pace, 0.25)), # 1st wuartile of pace
    Median = round(median(pace)), # median of pace
    Q3 = round(quantile(pace, 0.75)), #3rd quartile of pace
    Max = round(max(pace)), # maximum of pace
    Mean = mean(pace, 1)) %>% #mean of pace rounded so its not a long decimal
  arrange(factor(stress_level, levels = c("low", "medium", "high"))) #orders the levels
#create gt table
summary_table %>%
  gt() %>% #uses gt library
  tab_header(title = "Distribution of Reading Pace by Stress Level") %>% #heading of the table
  cols_label(
    stress_level = "Stress Level",
    Min= "Minimum",
    Q1 = "1st Quartile",
    Median = "Median",
    Q3 = "3rd Quartile",
    Max= "Maximum",
    Mean = "Mean") #column names

```

# 2. Affective Visualization
## 2A. Describe in words what an affective visualization could look like for your personal data

I could create a calendar with books instead of regular squares and they are colored in by stress level with a number of the pace on each book. I can add in notes in little bubbles connected to the books like bookmarks for the days I wrote observations like 're-read the same page 3 times' or 'sped through this.'

## 2B. Sketch
```{r, message=FALSE, echo=FALSE}
image<- image_read("/Users/sanjana/Desktop/ENVS-193DS/ENVS-193DS_homework-03/sketch.jpg")
grid::grid.raster(image)
```


## 2C. Visualization Draft

```{r}
image2<- image_read("/Users/sanjana/Desktop/ENVS-193DS/ENVS-193DS_homework-03/book_calendar.jpg")
grid::grid.raster(image2)
```

## 2D. Artist Statement

This piece visualizes my personal reading pace across days of with stress levels. Each book icon represents a day I read, color-coded by stress level(green-low, yellow- medium, coral- high) and labeled with how many pages I read per hour.

I was inspired by my life's saviour: google calender, and bullet journal youtube creators like Erin Smith and KB Journals. I track everything in my life down to the minute with my google calendar and I love how easy it is to just look at the page and know a lot of information through color coding, time blocks, and writing. But before I used gcal, I used bullet journals and the idea of using books as calendar units came from an old bullet journal spread I had in middle school, where I tracked which books I read which days(back when I read multiple books in a week)

The final piece is a digital hand-drawn calendar with color codes and written info made through Procreate.

I started with a template of books in a grid like a calendar and use the google sheet I made to add colors and pace to each book. Then using the Notes column I input short sentences about my qualitative observations and tried to make them look like bookmarks. 

# 3 Statistical Critique
## 3A. Revisit 
A two way ANOVA test is used in this study to assess differences in total number of microplastics
collected in low and high intertidal zones for spatial variability analysis and a repeated measures ANOVA test is used to asses temporal variabiity through differences in consecutive sampling events.

```{r}
image3<- image_read("/Users/sanjana/Desktop/ENVS-193DS/ENVS-193DS_homework-03/stat_critique.png")
grid::grid.raster(image3)
```


## 3B. Visual Clarity

The authors of this paper did represent their statistics clearly and appropriately through these figures. The axis makes sense in how they were named and where they were placed; the X axis values are tilted so they do not overlap. The first panel's X- axis has T1, T2, T3 to represent their transects and the second panel has sampling dates with time details (AM/PM). The Y axis in both are clearly labeled Microplastics/m² ± SE which gives infomration on how what units the data was measured with and that standard error bars are present. The bar height shows the means of microplastic abundance and the error bars using SE show variability and uncertainty around these means. There are patterning differences to differentiate low and high intertidal zones and a legend to interpret these patterns. The only issue with this plot is that the underlying data isn't shown. It should have been represented with raw data scatter points to correctly assess the distribution, sample size, outliers, etc to fully inform the reader. Another thing missing is there is no model prediction or fit even though ANOVA results are in the caption. 

## 3C. Aesthetic clarity
All the necessary elements like error bars, legends, labels, etc are included. There are no gridlines or unnecessary borders which reduces clutter and supports a good ink to data ratio. The labels and tick marks are not overcrowded and there was effort to make sure that they are readable but not redundant. The colors(grey) and patterns are consistent across both panels. There are patterning differences to differentiate low and high intertidal zones and a legend to interpret these patterns. 

## 3D. Recommendations
I would add underlying data jitter points on the graph to be transparent about sample size, variation/spread, outliers, etc. I would also use different contrasting colors rather than just different patterns to differentiate low and high intertidal zones because this is easier to see than grey patterns. I would also include p-values somewhere on the graph because readers should be able to quickly see key results and significance without reading the caption. I could also add sample size information somewhere on the group observations because while error bars are present, they depend on sample size and this graph doesnt show that context. I wouldnt remove anything from the graphs. 